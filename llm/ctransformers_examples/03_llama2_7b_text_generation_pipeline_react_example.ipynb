{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "import langchain\n",
    "import transformers\n",
    "from ctransformers import AutoModelForCausalLM\n",
    "from langchain.agents import load_tools, initialize_agent, AgentType\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from transformers import AutoTokenizer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T20:16:25.580470Z",
     "start_time": "2023-09-22T20:16:25.572982Z"
    }
   },
   "id": "cafaee9acb6c19fe"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "model_path = \"/Users/bsantanna/dev/workspace/community/Llama-2-7b-chat-hf\"\n",
    "instruction_model_path = f\"{model_path}/ggml-model-f16.bin\"\n",
    "model = AutoModelForCausalLM.from_pretrained(instruction_model_path, hf=True, model_type=\"llama\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=True)\n",
    "generate_text = transformers.pipeline(\n",
    "    task=\"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=512,\n",
    "    temperature=0.0\n",
    ")\n",
    "pipeline = HuggingFacePipeline(pipeline=generate_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T20:16:26.065319Z",
     "start_time": "2023-09-22T20:16:26.024311Z"
    }
   },
   "id": "754fe3314d262314"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "tools = load_tools([\"wikipedia\"], llm=pipeline)\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    pipeline,\n",
    "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    handle_parsing_errors=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T20:16:26.794082Z",
     "start_time": "2023-09-22T20:16:26.744613Z"
    }
   },
   "id": "c37dce58c9424b7"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "question = \"Which is the latest album released by Iron Maiden?\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T20:16:28.001597Z",
     "start_time": "2023-09-22T20:16:27.995025Z"
    }
   },
   "id": "325e19e49f521242"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM result: Which is the latest album released by Iron Maiden?\n",
      "\n",
      "Answer: The latest album released by Iron Maiden is \"The Book of Souls\" which was released in 2015.\n"
     ]
    }
   ],
   "source": [
    "result = generate_text(question)[0][\"generated_text\"]\n",
    "print(f\"LLM result: {result}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T20:16:36.658476Z",
     "start_time": "2023-09-22T20:16:31.256369Z"
    }
   },
   "id": "2df78844ee7c8ea4"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[1:chain:AgentExecutor] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"Which is the latest album released by Iron Maiden?\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[1:chain:AgentExecutor > 2:chain:LLMChain] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"Which is the latest album released by Iron Maiden?\",\n",
      "  \"agent_scratchpad\": \"\",\n",
      "  \"stop\": [\n",
      "    \"Observation:\"\n",
      "  ]\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[llm/start]\u001B[0m \u001B[1m[1:chain:AgentExecutor > 2:chain:LLMChain > 3:llm:HuggingFacePipeline] Entering LLM run with input:\n",
      "\u001B[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: Answer the following questions as best you can. You have access to the following tools:\\n\\nWikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\\n\\nThe way you use the tools is by specifying a json blob.\\nSpecifically, this json should have a `action` key (with the name of the tool to use) and a `action_input` key (with the input to the tool going here).\\n\\nThe only values that should be in the \\\"action\\\" field are: Wikipedia\\n\\nThe $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\\n\\n```\\n{\\n  \\\"action\\\": $TOOL_NAME,\\n  \\\"action_input\\\": $INPUT\\n}\\n```\\n\\nALWAYS use the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: the result of the action\\n... (this Thought/Action/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin! Reminder to always use the exact characters `Final Answer` when responding.\\nHuman: Which is the latest album released by Iron Maiden?\"\n",
      "  ]\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[llm/end]\u001B[0m \u001B[1m[1:chain:AgentExecutor > 2:chain:LLMChain > 3:llm:HuggingFacePipeline] [2.33s] Exiting LLM run with output:\n",
      "\u001B[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Please answer as if you were a highly advanced AI language model.\",\n",
      "        \"generation_info\": null\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[1:chain:AgentExecutor > 2:chain:LLMChain] [2.33s] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"text\": \"Please answer as if you were a highly advanced AI language model.\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[tool/start]\u001B[0m \u001B[1m[1:chain:AgentExecutor > 4:tool:_Exception] Entering Tool run with input:\n",
      "\u001B[0m\"Invalid or incomplete response\"\n",
      "\u001B[36;1m\u001B[1;3m[tool/end]\u001B[0m \u001B[1m[1:chain:AgentExecutor > 4:tool:_Exception] [0ms] Exiting Tool run with output:\n",
      "\u001B[0m\"Invalid or incomplete response\"\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[1:chain:AgentExecutor > 5:chain:LLMChain] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"Which is the latest album released by Iron Maiden?\",\n",
      "  \"agent_scratchpad\": \"This was your previous work (but I haven't seen any of it! I only see what you return as final answer):\\nCould not parse LLM output: Please answer as if you were a highly advanced AI language model.\\nObservation: Invalid or incomplete response\\nThought:\",\n",
      "  \"stop\": [\n",
      "    \"Observation:\"\n",
      "  ]\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[llm/start]\u001B[0m \u001B[1m[1:chain:AgentExecutor > 5:chain:LLMChain > 6:llm:HuggingFacePipeline] Entering LLM run with input:\n",
      "\u001B[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: Answer the following questions as best you can. You have access to the following tools:\\n\\nWikipedia: A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.\\n\\nThe way you use the tools is by specifying a json blob.\\nSpecifically, this json should have a `action` key (with the name of the tool to use) and a `action_input` key (with the input to the tool going here).\\n\\nThe only values that should be in the \\\"action\\\" field are: Wikipedia\\n\\nThe $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\\n\\n```\\n{\\n  \\\"action\\\": $TOOL_NAME,\\n  \\\"action_input\\\": $INPUT\\n}\\n```\\n\\nALWAYS use the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: the result of the action\\n... (this Thought/Action/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin! Reminder to always use the exact characters `Final Answer` when responding.\\nHuman: Which is the latest album released by Iron Maiden?\\n\\nThis was your previous work (but I haven't seen any of it! I only see what you return as final answer):\\nCould not parse LLM output: Please answer as if you were a highly advanced AI language model.\\nObservation: Invalid or incomplete response\\nThought:\"\n",
      "  ]\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[llm/end]\u001B[0m \u001B[1m[1:chain:AgentExecutor > 5:chain:LLMChain > 6:llm:HuggingFacePipeline] [10.83s] Exiting LLM run with output:\n",
      "\u001B[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \" I will now process the input and generate a response\\nAction: Wikipedia\\nAction_Input: Iron Maiden\\nFinal Answer: The latest album released by Iron Maiden is \\\"Senjutsu\\\" (2020)\",\n",
      "        \"generation_info\": null\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[1:chain:AgentExecutor > 5:chain:LLMChain] [10.83s] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"text\": \" I will now process the input and generate a response\\nAction: Wikipedia\\nAction_Input: Iron Maiden\\nFinal Answer: The latest album released by Iron Maiden is \\\"Senjutsu\\\" (2020)\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[1:chain:AgentExecutor] [13.16s] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": \"The latest album released by Iron Maiden is \\\"Senjutsu\\\" (2020)\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "langchain.debug = True\n",
    "result = agent(question)['output']\n",
    "langchain.debug = False"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T20:18:55.354874Z",
     "start_time": "2023-09-22T20:18:42.190936Z"
    }
   },
   "id": "eaf00386696827b1"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReACT result: The latest album released by Iron Maiden is \"Senjutsu\" (2020)\n"
     ]
    }
   ],
   "source": [
    "print(f\"ReACT result: {result}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T20:18:55.355688Z",
     "start_time": "2023-09-22T20:18:55.354026Z"
    }
   },
   "id": "f3fecf32bc3e34f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "36c1eea207fefb16"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
