{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-15T16:24:55.375924Z",
     "start_time": "2023-08-15T16:24:55.373538Z"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install --upgrade langchain  wikipedia\n",
    "#!CMAKE_ARGS=\"-DLLAMA_METAL=on\" FORCE_CMAKE=1 pip install --upgrade llama-cpp-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools, initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain.llms import LlamaCpp"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T16:24:58.197823Z",
     "start_time": "2023-08-15T16:24:55.379204Z"
    }
   },
   "id": "47ef36ae0cc40391"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Globals\n",
    "instruction_model_path = \"/Users/bsantanna/dev/workspace/community/Llama-2-7b-chat-hf/ggml-model-f16.bin\"\n",
    "n_gpu_layers = 1\n",
    "n_batch = 512"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T16:24:58.200794Z",
     "start_time": "2023-08-15T16:24:58.197993Z"
    }
   },
   "id": "decaa2eeb7c9a639"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama.cpp: loading model from /Users/bsantanna/dev/workspace/community/Llama-2-7b-chat-hf/ggml-model-f16.bin\n",
      "llama_model_load_internal: format     = ggjt v1 (pre #1405)\n",
      "llama_model_load_internal: n_vocab    = 32000\n",
      "llama_model_load_internal: n_ctx      = 2048\n",
      "llama_model_load_internal: n_embd     = 4096\n",
      "llama_model_load_internal: n_mult     = 5504\n",
      "llama_model_load_internal: n_head     = 32\n",
      "llama_model_load_internal: n_head_kv  = 32\n",
      "llama_model_load_internal: n_layer    = 32\n",
      "llama_model_load_internal: n_rot      = 128\n",
      "llama_model_load_internal: n_gqa      = 1\n",
      "llama_model_load_internal: rnorm_eps  = 1.0e-06\n",
      "llama_model_load_internal: n_ff       = 11008\n",
      "llama_model_load_internal: freq_base  = 10000.0\n",
      "llama_model_load_internal: freq_scale = 1\n",
      "llama_model_load_internal: ftype      = 1 (mostly F16)\n",
      "llama_model_load_internal: model size = 7B\n",
      "llama_model_load_internal: ggml ctx size =    0.08 MB\n",
      "llama_model_load_internal: mem required  = 13251.10 MB (+ 1024.00 MB per state)\n",
      "llama_new_context_with_model: kv self size  = 1024.00 MB\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: using MPS\n",
      "ggml_metal_init: loading '/Users/bsantanna/miniforge3/envs/ml/lib/python3.11/site-packages/llama_cpp/ggml-metal.metal'\n",
      "ggml_metal_init: loaded kernel_add                            0x10edf3090\n",
      "ggml_metal_init: loaded kernel_add_row                        0x10f50e110\n",
      "ggml_metal_init: loaded kernel_mul                            0x10f50e430\n",
      "ggml_metal_init: loaded kernel_mul_row                        0x10f50e690\n",
      "ggml_metal_init: loaded kernel_scale                          0x10f50e8f0\n",
      "ggml_metal_init: loaded kernel_silu                           0x10f50eb50\n",
      "ggml_metal_init: loaded kernel_relu                           0x10f50edb0\n",
      "ggml_metal_init: loaded kernel_gelu                           0x10f50f010\n",
      "ggml_metal_init: loaded kernel_soft_max                       0x10f50f270\n",
      "ggml_metal_init: loaded kernel_diag_mask_inf                  0x10f50f4d0\n",
      "ggml_metal_init: loaded kernel_get_rows_f16                   0x10f50f730\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_0                  0x10f50f990\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_1                  0x10f50fbf0\n",
      "ggml_metal_init: loaded kernel_get_rows_q2_K                  0x10f50fe50\n",
      "ggml_metal_init: loaded kernel_get_rows_q3_K                  0x10f5100b0\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_K                  0x10f510310\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_K                  0x10f510570\n",
      "ggml_metal_init: loaded kernel_get_rows_q6_K                  0x10f5107d0\n",
      "ggml_metal_init: loaded kernel_rms_norm                       0x10f510a30\n",
      "ggml_metal_init: loaded kernel_norm                           0x10f510c90\n",
      "ggml_metal_init: loaded kernel_mul_mat_f16_f32                0x10f511230\n",
      "ggml_metal_init: loaded kernel_mul_mat_q4_0_f32               0x10f511490\n",
      "ggml_metal_init: loaded kernel_mul_mat_q4_1_f32               0x10f5116f0\n",
      "ggml_metal_init: loaded kernel_mul_mat_q2_K_f32               0x10f511950\n",
      "ggml_metal_init: loaded kernel_mul_mat_q3_K_f32               0x10f511bb0\n",
      "ggml_metal_init: loaded kernel_mul_mat_q4_K_f32               0x10f511e10\n",
      "ggml_metal_init: loaded kernel_mul_mat_q5_K_f32               0x10f512070\n",
      "ggml_metal_init: loaded kernel_mul_mat_q6_K_f32               0x10f5122d0\n",
      "ggml_metal_init: loaded kernel_rope                           0x10f512530\n",
      "ggml_metal_init: loaded kernel_alibi_f32                      0x10f512b30\n",
      "ggml_metal_init: loaded kernel_cpy_f32_f16                    0x10f513100\n",
      "ggml_metal_init: loaded kernel_cpy_f32_f32                    0x10f5136d0\n",
      "ggml_metal_init: loaded kernel_cpy_f16_f16                    0x10f513ca0\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize = 49152.00 MB\n",
      "ggml_metal_init: hasUnifiedMemory             = true\n",
      "ggml_metal_init: maxTransferRate              = built-in GPU\n",
      "llama_new_context_with_model: max tensor size =   250.00 MB\n",
      "ggml_metal_add_buffer: allocated 'data            ' buffer, size = 12853.45 MB, (12853.91 / 49152.00)\n",
      "ggml_metal_add_buffer: allocated 'eval            ' buffer, size =    10.00 MB, (12863.91 / 49152.00)\n",
      "ggml_metal_add_buffer: allocated 'kv              ' buffer, size =  1026.00 MB, (13889.91 / 49152.00)\n",
      "ggml_metal_add_buffer: allocated 'scr0            ' buffer, size =   228.00 MB, (14117.91 / 49152.00)\n",
      "ggml_metal_add_buffer: allocated 'scr1            ' buffer, size =   160.00 MB, (14277.91 / 49152.00)\n"
     ]
    }
   ],
   "source": [
    "# Load LLM instruction following model\n",
    "llm = LlamaCpp(\n",
    "    model_path=instruction_model_path,\n",
    "    n_gpu_layers=n_gpu_layers,\n",
    "    n_batch=n_batch,\n",
    "    f16_kv=True,\n",
    "    verbose=False,\n",
    "    n_ctx=2048\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T16:24:58.431314Z",
     "start_time": "2023-08-15T16:24:58.200607Z"
    }
   },
   "id": "57431d059860df00"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "tools = load_tools([\"wikipedia\"], llm=llm)\n",
    "\n",
    "agent= initialize_agent(\n",
    "    tools, \n",
    "    llm, \n",
    "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    handle_parsing_errors=True,\n",
    "    verbose = True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T16:24:58.542124Z",
     "start_time": "2023-08-15T16:24:58.430793Z"
    }
   },
   "id": "caaed4dc6ebd3285"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3mCould not parse LLM output: Please provide your answer in a valid $JSON_BLOB format.\u001B[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001B[32;1m\u001B[1;3m I will now use Wikipedia to find the capital of Brazil.\n",
      "Action: Wikipedia ($action_input should be the search query)\n",
      "Final Answer: The capital of Brazil is Brasília.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "{'input': 'Use wikipedia for replying the following question: Which city is the capital of Brazil?', 'output': 'The capital of Brazil is Brasília.'}\n"
     ]
    }
   ],
   "source": [
    "question = \"Use wikipedia for replying the following question: Which city is the capital of Brazil?\"\n",
    "result = agent(question) \n",
    "print(result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T16:25:12.840558Z",
     "start_time": "2023-08-15T16:24:58.540761Z"
    }
   },
   "id": "2f322bcaaaefead7"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3mCould not parse LLM output: \n",
      "This is a multi-part question. When answering, please address each part of the question separately.\n",
      "How do you plan to answer this question? \u001B[0m\n",
      "Observation: Invalid or incomplete response\n",
      "Thought:\u001B[32;1m\u001B[1;3m I will use Wikipedia to find information about Neymar and his achievements.\n",
      "Action: {\n",
      "  \"action\": \"Wikipedia\",\n",
      "  \"action_input\": \"Neymar\"\n",
      "}\n",
      "Final Answer: Neymar is a Brazilian professional footballer who plays as a forward for Paris Saint-Germain and the Brazil national team. He is known for his speed, skill, and goal-scoring ability on the field. Off the field, he has been in the media spotlight for his personal life, including his high-profile relationships and endorsement deals.\n",
      "Please provide your next question or thought.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "{'input': 'Use wikipedia for replying the following question: Who is Neymar and what he is known for?', 'output': 'Neymar is a Brazilian professional footballer who plays as a forward for Paris Saint-Germain and the Brazil national team. He is known for his speed, skill, and goal-scoring ability on the field. Off the field, he has been in the media spotlight for his personal life, including his high-profile relationships and endorsement deals.\\nPlease provide your next question or thought.'}\n"
     ]
    }
   ],
   "source": [
    "question = \"Use wikipedia for replying the following question: Who is Neymar and what he is known for?\"\n",
    "result = agent(question) \n",
    "print(result)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T16:26:22.406118Z",
     "start_time": "2023-08-15T16:26:07.994839Z"
    }
   },
   "id": "643fed5a97e21a92"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-15T16:25:34.025846Z",
     "start_time": "2023-08-15T16:25:34.024267Z"
    }
   },
   "id": "ea38200d58b51c35"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
