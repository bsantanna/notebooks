{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# !pip install --upgrade langchain accelerate transformers sentencepiece\n",
    "# !pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cpu\n",
    "!export PYTORCH_ENABLE_MPS_FALLBACK=1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T16:23:13.696148Z",
     "start_time": "2023-08-08T16:23:13.571158Z"
    }
   },
   "id": "4303a7defcd16f3f"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bsantanna/miniforge3/envs/ml/lib/python3.11/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from transformers import pipeline, T5Tokenizer, T5ForConditionalGeneration"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T16:23:18.805670Z",
     "start_time": "2023-08-08T16:23:13.698661Z"
    }
   },
   "id": "6bb9fe6fc1b3ceaf"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "data": {
      "text/plain": "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b35d04bf79fd4e6eb009cc8c372701f5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# initialize LLM\n",
    "instruction_model = 'google/flan-t5-xxl'\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(instruction_model)\n",
    "model = T5ForConditionalGeneration.from_pretrained(instruction_model, device_map=\"auto\", offload_folder=\"/tmp/offload\")\n",
    "\n",
    "generate_text = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    max_length=1000,\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "transformer_pipeline = HuggingFacePipeline(pipeline=generate_text)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T16:24:36.699560Z",
     "start_time": "2023-08-08T16:23:18.806581Z"
    }
   },
   "id": "e1ef56d3fa6a1159"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "# Initialize documents\n",
    "file = 'dataset/wine_100.csv'\n",
    "loader = CSVLoader(file_path=file)\n",
    "\n",
    "# initialize embeddings\n",
    "embedding_model = 'hkunlp/instructor-xl'\n",
    "embedding = HuggingFaceInstructEmbeddings(model_name=embedding_model)\n",
    "index = VectorstoreIndexCreator(\n",
    "    embedding=embedding,\n",
    "    vectorstore_cls=DocArrayInMemorySearch\n",
    ").from_loaders([loader])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T16:25:06.622747Z",
     "start_time": "2023-08-08T16:24:36.700160Z"
    }
   },
   "id": "141c59e626bb5c74"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# initialize db \n",
    "docs = loader.load()\n",
    "db = DocArrayInMemorySearch.from_documents(\n",
    "    docs, \n",
    "    embedding\n",
    ")\n",
    "\n",
    "# initialize retriever\n",
    "retriever = db.as_retriever()\n",
    "\n",
    "# initialize chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=transformer_pipeline, \n",
    "    chain_type=\"stuff\", # map_reduce, refine, map_rerank\n",
    "    retriever=retriever, \n",
    "    verbose=True\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T16:25:29.278491Z",
     "start_time": "2023-08-08T16:25:06.624315Z"
    }
   },
   "id": "c1fcb22f953105b5"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new RetrievalQA chain...\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "Canicatt 2009 Aynat Nero d'Avola (Sicilia)\n"
     ]
    }
   ],
   "source": [
    "# Query\n",
    "query = \"Recommend me a nice wine from Italy.\"\n",
    "response = qa_chain.run(query)\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T16:27:16.311103Z",
     "start_time": "2023-08-08T16:25:29.281780Z"
    }
   },
   "id": "fb98303ce8201c88"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new RetrievalQA chain...\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "Tres Palacios 2011 Reserve Pinot Noir (Maipo Valley) and Sundance 2011 Merlot (Maule Valley)\n"
     ]
    }
   ],
   "source": [
    "# Query\n",
    "query = \"Recommend me two nice wines from Chile.\"\n",
    "response = qa_chain.run(query)\n",
    "print(response)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T16:28:06.042839Z",
     "start_time": "2023-08-08T16:27:16.316759Z"
    }
   },
   "id": "493660ee9cef3174"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-08T16:28:06.048231Z",
     "start_time": "2023-08-08T16:28:06.040147Z"
    }
   },
   "id": "1280368806b00e1d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
