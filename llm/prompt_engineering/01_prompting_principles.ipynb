{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Guidelines for prompting\n",
    "\n",
    "Goal of this notebook is practicing and understanding prompting principles.\n",
    "\n",
    "Examples sourced from [Deeplearning.ai ChatGPT Prompt Engineering for Developers](https://learn.deeplearning.ai/chatgpt-prompt-eng/lesson/2/guidelines) course.\n",
    "\n",
    "LLM Model: [dolly-v2-3b](https://huggingface.co/databricks/dolly-v2-3b)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!export PYTORCH_ENABLE_MPS_FALLBACK=1\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from transformers import pipeline\n",
    "\n",
    "# print(torch.backends.mps.is_available())\n",
    "# print(torch.backends.mps.is_built())\n",
    "# print(torch.cuda.is_available())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T12:41:25.906243Z",
     "start_time": "2023-05-18T12:41:25.772501Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "af69a0ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-18T10:07:38.687104Z",
     "start_time": "2023-05-18T10:07:35.902027Z"
    }
   },
   "outputs": [],
   "source": [
    "generate_text = pipeline(model=\"databricks/dolly-v2-3b\", torch_dtype=torch.bfloat16,\n",
    "                         trust_remote_code=True, device_map=\"auto\", return_full_text=True)\n",
    "\n",
    "simple_prompt = PromptTemplate(\n",
    "    input_variables=[\"instruction\"],\n",
    "    template=\"{instruction}\")\n",
    "\n",
    "prompt_with_context = PromptTemplate(\n",
    "    input_variables=[\"instruction\", \"context\"],\n",
    "    template=\"{instruction}\\n\\nInput:\\n{context}\")\n",
    "\n",
    "hf_pipeline = HuggingFacePipeline(pipeline=generate_text)\n",
    "\n",
    "llm_chain = LLMChain(llm=hf_pipeline, prompt=simple_prompt)\n",
    "llm_context_chain = LLMChain(llm=hf_pipeline, prompt=prompt_with_context)\n",
    "\n",
    "\n",
    "def get_response(input_prompt, context=None):\n",
    "    if context is None:\n",
    "        return llm_chain.predict(instruction=input_prompt).lstrip()\n",
    "    else:\n",
    "        return llm_context_chain.predict(instruction=input_prompt, context=context).lstrip()\n",
    "\n",
    "\n",
    "def reply_prompt(input_prompt, context=None):\n",
    "    start = time.time()\n",
    "    response = get_response(input_prompt, context)\n",
    "    end = time.time()\n",
    "    duration_seconds = end - start\n",
    "    print(response)\n",
    "    print(f\"\\nProcessing duration: {duration_seconds:0.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9a33cb43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-18T10:08:17.223922Z",
     "start_time": "2023-05-18T10:07:41.896854Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of United Kingdom is London.\n",
      "\n",
      "Processing duration: 35.33 seconds\n"
     ]
    }
   ],
   "source": [
    "text = f\"\"\"\n",
    "What is the capital of United Kingdom?\n",
    "\"\"\"\n",
    "prompt = f\"\"\"\n",
    "Reply the question delimited by <> in a single sentence.\n",
    "<{text}>\n",
    "\"\"\"\n",
    "reply_prompt(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c43460",
   "metadata": {},
   "source": [
    "## Prompting Principles\n",
    "- **Principle 1: Write clear and specific instructions**\n",
    "- **Principle 2: Give the model time to “think”**\n",
    "\n",
    "### Principle 1: Write clear and specific instructions\n",
    "\n",
    "#### Tactics\n",
    "\n",
    "##### Tactic 1: Use delimiters to clearly indicate distinct parts of the input\n",
    "- Delimiters can be anything like: ```, \"\"\", < >, `<tag> </tag>`, `:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ceccdc37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-18T10:20:35.988916Z",
     "start_time": "2023-05-18T10:19:14.761397Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clear and specific\n",
      "\n",
      "Processing duration: 81.23 seconds\n"
     ]
    }
   ],
   "source": [
    "text = f\"\"\"\n",
    "You should express what you want a model to do by providing instructions that are as clear and specific as you can possibly make them. This will guide the model towards the desired output, and reduce the chances of receiving irrelevant or incorrect responses. Don't confuse writing a clear prompt with writing a short prompt. In many cases, longer prompts provide more clarity and context for the model, which can lead to more detailed and relevant outputs.\n",
    "\"\"\"\n",
    "prompt = f\"\"\"\n",
    "Summarize the text delimited by triple backticks using few words.\n",
    "```{text}```\n",
    "\"\"\"\n",
    "reply_prompt(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c535ded",
   "metadata": {},
   "source": [
    "##### Tactic 2: Ask for a structured output\n",
    "- JSON, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "745e2ee4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-18T10:15:58.965523Z",
     "start_time": "2023-05-18T10:13:42.033362Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a list of three book titles and their authors and genres:\n",
      "{\n",
      "  \"book_id\": 1,\n",
      "  \"title\": \"Harry Potter and the Methods of Rhythm\",\n",
      "  \"author\": \"JK Rowling\",\n",
      "  \"genre\": \"Fantasy\"\n",
      "},\n",
      "{\n",
      "  \"book_id\": 2,\n",
      "  \"title\": \"The Joy of Telegraph\",\n",
      "  \"author\": \"Telegraph\",\n",
      "  \"genre\": \" humour\"\n",
      "},\n",
      "{\n",
      "  \"book_id\": 3,\n",
      "  \"title\": \"Silence is Death\",\n",
      "  \"author\": \"Shirley Conte\",\n",
      "  \"genre\": \" Horror\"\n",
      "}\n",
      "\n",
      "Processing duration: 136.93 seconds\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Generate a list of three made-up book titles along with their authors and genres.\n",
    "Provide them as a list in JSON format with the following keys: book_id, title, author, genre.\n",
    "\"\"\"\n",
    "reply_prompt(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc232a4",
   "metadata": {},
   "source": [
    "##### Tactic 3: Ask the model to check whether conditions are satisfied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "28270aa8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-18T10:36:59.761308Z",
     "start_time": "2023-05-18T10:34:03.616376Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 - Grab some water boiling\n",
      "Step 2 - while that's happening, grab a cup and put a tea bag in it\n",
      "Step 3 - pour it over the tea bag\n",
      "Step 4 - let it sit for a bit so the tea can steep\n",
      "Step 5 - after a few minutes, take out the tea bag\n",
      "Step 6 - if you like, you can add some sugar or milk to taste\n",
      "\n",
      "Processing duration: 176.14 seconds\n"
     ]
    }
   ],
   "source": [
    "text = f\"\"\"\n",
    "Making a cup of tea is easy! First, you need to get some water boiling. While that's happening, grab a cup and put a tea bag in it. Once the water is hot enough, just pour it over the tea bag. Let it sit for a bit so the tea can steep. After a few minutes, take out the tea bag. If you like, you can add some sugar or milk to taste. And that's it! You've got yourself a delicious cup of tea to enjoy.\n",
    "\"\"\"\n",
    "prompt = f\"\"\"\n",
    "You will be provided with text delimited by <>. \n",
    "If it contains a sequence of steps, re-write those steps in the following format:\n",
    "\n",
    "Step 1 - ...\n",
    "Step 2 - ...\n",
    "Step 3 - ...\n",
    "...\n",
    "Step N - ...\n",
    "\n",
    "If the text does not contain a sequence of steps, write nothing.\"\n",
    "\n",
    "<{text}>\n",
    "\"\"\"\n",
    "\n",
    "reply_prompt(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04bb589",
   "metadata": {},
   "source": [
    "##### Tactic 4: \"Few-shot\" prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b0270bd5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-18T11:03:35.391866Z",
     "start_time": "2023-05-18T11:00:16.931957Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patience is a virtue. Resilience is a trait you acquire through hard work. Both are essential to human nature. To better understand patience, consider the paradox: Perseverance is often harder than the initial attempt. Patience allows you to wait for what's to come; it also allows you to be comfortable with uncertainty. The more you practice patience, the easier it becomes. Resilience, on the other hand, is something that can be cultivated. Consider also: In sports, the best athletes always learn from their failures, and never quit when things get difficult. Resilience is a hard-willed quality, and requires you to be unafraid of failure. To build resilience, you have to put things into perspective and not get too caught up in the moment. In summary, patience is a virtue you acquire through experience, and resilience is a hard-willed quality that can be cultivated.\n",
      "\n",
      "Processing duration: 198.46 seconds\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "You will receive a dialog between two characters delimited by triple backticks.\n",
    "Your task is to explain the concept asked by <child> following the style of <grandparent>.\n",
    "\n",
    "```\n",
    "<child>: Teach me about patience.\n",
    "\n",
    "<grandparent>: The river that carves the deepest valley flows from a modest spring; the grandest symphony originates from a single note; the most intricate tapestry begins with a solitary thread.\n",
    "\n",
    "<child>: Teach me about resilience.\n",
    "```\n",
    "\n",
    "\"\"\"\n",
    "reply_prompt(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0768b589",
   "metadata": {},
   "source": [
    "### Principle 2: Give the model time to “think” \n",
    "\n",
    "#### Tactic 1: Specify the steps required to complete a task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d6a860eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-18T12:39:38.377627Z",
     "start_time": "2023-05-18T12:37:18.638322Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"summary\":\"In a charming village, siblings Jack and Jill set out on a quest to fetch water from a hilltop well.\",\n",
      "  \"num_names\": \"2\"\n",
      "}\n",
      "\n",
      "Processing duration: 139.74 seconds\n"
     ]
    }
   ],
   "source": [
    "text = f\"\"\"\n",
    "In a charming village, siblings Jack and Jill set out on a quest to fetch water from a hilltop well. As they climbed, singing joyfully, misfortune struck—Jack tripped on a stone and tumbled down the hill, with Jill following suit. Though slightly battered, the pair returned home to comforting embraces. Despite the mishap, their adventurous spirits remained undimmed, and they continued exploring with delight.\n",
    "\"\"\"\n",
    "# example 1\n",
    "prompt_1 = f\"\"\"\n",
    "Perform the following actions: \n",
    "1 - Summarize the following text delimited by <> with at most 100 characters.\n",
    "2 - List each name from the text.\n",
    "3 - Output a JSON object that contains the following keys: summary, num_names.\n",
    "\n",
    "Separate your answers with line breaks.\n",
    "\n",
    "Text:\n",
    "<{text}>\n",
    "\"\"\"\n",
    "\n",
    "reply_prompt(prompt_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751c9010",
   "metadata": {},
   "source": [
    "##### Tactic 2: Instruct the model to work out its own solution before rushing to a conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e3684b81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-18T12:33:44.342482Z",
     "start_time": "2023-05-18T12:32:06.837270Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No, the square root of 9 is not an even number.\n",
      "\n",
      "Processing duration: 97.51 seconds\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to determine if the student's solution is correct or not.\n",
    "\n",
    "To solve the problem do the following:\n",
    "- First, work out your own solution to the problem. \n",
    "- Then compare your solution to the student's solution and evaluate if the student's solution is correct or not.\n",
    "\n",
    "Don't decide if the student's solution is correct until you have done the problem yourself.\n",
    "\n",
    "Question: 'Is the square root of 9 an odd number?'\n",
    "\n",
    "Student's solution: 'No square root of 9 is an even number.'\n",
    "\n",
    "Comparison of both solutions: ...\n",
    "\"\"\"\n",
    "reply_prompt(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755baf01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
