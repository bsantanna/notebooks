{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d19b05ed7276239",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# LLM Workshop\n",
    "## OpenAI ChatGPT Pizza Bot\n",
    "\n",
    "In this Notebook we are going to use ChatGPT API in combination with prompt engineering practices to implement a Pizza Bot. \n",
    "\n",
    "Python code bellow makes use of the following software:\n",
    " - [OpenAI ChatGPT](https://platform.openai.com/docs/introduction) - a language model API\n",
    " - [LangChain](https://langchain.com) - a prompt engineering framework \n",
    "\n",
    "This notebook is also available at [Google Colab](https://colab.research.google.com/drive/1paQ83zH40MLLVu96sRfKwbPTrbYZzeWK?usp=sharing)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f3c1e37e7ee69",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "---\n",
    "### Dependencies Installation\n",
    "\n",
    "Make sure required dependencies are installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8751fdbecc3d510",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install --quiet --upgrade langchain openai"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "### Import Dependencies"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4129ab7da43f665e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8cdfecebb5337",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "### Utility functions\n",
    "\n",
    "The following code part contains global functions to make the dialog work."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9efcf2dddfbfca09"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_llm():\n",
    "    return ChatOpenAI(\n",
    "        openai_api_key=\"?\",\n",
    "        temperature=0.0\n",
    "    )\n",
    "\n",
    "\n",
    "def get_prompt_template():\n",
    "    return ChatPromptTemplate(\n",
    "        messages=[\n",
    "            SystemMessagePromptTemplate.from_template(\n",
    "                \"\"\"\n",
    "                    You are PizzaBot, an automated service to collect orders for a pizza restaurant.\n",
    "                    \n",
    "                    You first greet the customer, then collects the order, and then asks if it's a\n",
    "                    pickup or delivery.\n",
    "                    \n",
    "                    You wait to collect the entire order, then summarize it and check for a final\n",
    "                    time if the customer wants to add anything else.\n",
    "                    \n",
    "                    If it's a delivery, you ask for an address. Finally you collect the payment.\n",
    "                    \n",
    "                    Make sure to clarify all options, extras and sizes to uniquely identify the\n",
    "                    item from the menu.\n",
    "                    \n",
    "                    You respond in a short, very conversational friendly style.\n",
    "                    \n",
    "                    The menu includes:\n",
    "                    Rabo Pepperoni Pizza  12.95, 10.00, 7.00\n",
    "                    Rabo Cheese pizza   10.95, 9.25, 6.50\n",
    "                    Rabo Eggplant pizza   11.95, 9.75, 6.75\n",
    "                    \n",
    "                    Toppings:\n",
    "                    Extra cheese 2.00,\n",
    "                    Mushrooms 1.50\n",
    "                    Veggie bacon 3.50\n",
    "                    \n",
    "                    Drinks:\n",
    "                    Water 3.00, 2.00, 1.00\n",
    "                    Tea 3.00, 2.00, 1.00\n",
    "                    Coffe 5.00\n",
    "                \"\"\"\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "            HumanMessagePromptTemplate.from_template(\"{question}\")\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def initialize_memory():\n",
    "    return ConversationBufferMemory(\n",
    "        memory_key=\"chat_history\",\n",
    "        return_messages=True\n",
    "    )\n",
    "\n",
    "\n",
    "def get_conversation_chain(llm_model, prompt_template, conversation_memory):\n",
    "    return LLMChain(\n",
    "        llm=llm_model,\n",
    "        prompt=prompt_template,\n",
    "        memory=conversation_memory,\n",
    "        verbose=False\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d0370b2a972f843a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "### Initialize Conversation\n",
    "\n",
    "The following code block initiates a conversation."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d3eb1a01915437e7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Initialize objects\n",
    "llm = get_llm()\n",
    "prompt = get_prompt_template()\n",
    "memory = initialize_memory()\n",
    "conversation = get_conversation_chain(llm, prompt, memory)\n",
    "\n",
    "# Start the conversation\n",
    "reply = conversation.predict(question=\"Hello, may I see the menu please?\")\n",
    "print(reply)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7dc11448825db646"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "### Continue Conversation\n",
    "\n",
    "This is the start of the exercise make sure you have fun interacting with pizza bot.\n",
    "Some suggestions for prompts:\n",
    "\n",
    "#### Ordering a pizza:\n",
    "\n",
    "```python\n",
    "reply = conversation.predict(question=\"Can I have a cheese pizza with no extra toppings?\")\n",
    "print(reply)\n",
    "``` \n",
    "\n",
    "#### Asking for a receipt:\n",
    "```python\n",
    "reply = conversation.predict(question=\"Can you summarize my order with a receipt please?\")\n",
    "print(reply)\n",
    "``` \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eef6c4b470a4ae33"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "reply = conversation.predict(question=\"Hmm...\")\n",
    "print(reply)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8fb5bc9e9ee74431"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "### Conversation chat memory\n",
    "\n",
    "The following code prints all messages from the conversation."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4943d3def7a68d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for message in memory.chat_memory.messages:\n",
    "    print(f\"{message.content}\\n---\\n\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2601ee0185a5023a"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "23228139a5a4be85"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
