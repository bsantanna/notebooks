{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d19b05ed7276239",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# LLM Workshop\n",
    "## OpenAI ChatGPT LLM Warmup\n",
    "\n",
    "In this Notebook we are going to use ChatGPT API to practice prompt engineering.\n",
    "\n",
    "Python code bellow makes use of the following software:\n",
    " - [OpenAI ChatGPT](https://platform.openai.com/docs/introduction) - a language model API\n",
    " - [LangChain](https://langchain.com) - a prompt engineering framework \n",
    "\n",
    "This notebook is also available at [Google Colab](https://colab.research.google.com/drive/1ofG97M-drPwKbQbwwxqEk0Vt7jxt9Vyw?usp=sharing)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f3c1e37e7ee69",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "---\n",
    "### Dependencies Installation\n",
    "\n",
    "Make sure required dependencies are installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8751fdbecc3d510",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install --quiet --upgrade langchain openai"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "### Import Dependencies"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4129ab7da43f665e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8cdfecebb5337",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "### Utility functions\n",
    "\n",
    "The following code part contains global functions to make the dialog work."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9efcf2dddfbfca09"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_llm():\n",
    "    return ChatOpenAI(\n",
    "        openai_api_key=\"?\",\n",
    "        temperature=0.0\n",
    "    )\n",
    "\n",
    "\n",
    "def get_sequential_chain(llm, first_instruction, second_instruction):\n",
    "    first_prompt = ChatPromptTemplate.from_template(first_instruction)\n",
    "    chain_one = LLMChain(llm=llm, prompt=first_prompt)\n",
    "\n",
    "    second_prompt = ChatPromptTemplate.from_template(second_instruction)\n",
    "    chain_two = LLMChain(llm=llm, prompt=second_prompt)\n",
    "\n",
    "    return SimpleSequentialChain(\n",
    "        chains=[chain_one, chain_two],\n",
    "        verbose=False\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d0370b2a972f843a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "### Initialize LLM"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d3eb1a01915437e7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "llm = get_llm()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7dc11448825db646"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "### General prompt techniques\n",
    "\n",
    "- Character delimiters\n",
    "- Conditional processing \n",
    "- Output formatting\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a30f26723df84b29"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "question = \"2+2\"\n",
    "language = \"dutch\"\n",
    "instruction = f\"\"\"\n",
    "Determine the answer for the question delimited by <>, \n",
    "after that reply the answer in {language}, \n",
    "if it is a number, write only the number written as full word. \n",
    "Short answer, no explanation.\n",
    " \n",
    " <{question}>\n",
    " \n",
    "\"\"\"\n",
    "reply = llm.predict(instruction)\n",
    "print(reply)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2601ee0185a5023a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "### Multiple Step Prompt"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b67c23c71982992"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "product_suggestions_chain = get_sequential_chain(\n",
    "    llm,\n",
    "    first_instruction=\"What is the best name to describe a company that makes {product}?\",\n",
    "    second_instruction=\"Write a 30 words description for the following company:{company_name}\"\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c9595a100f17f40"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "reply = product_suggestions_chain.run(\"Luxury watches\")\n",
    "print(reply)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "388c365b6ff73e83"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "21235a7e45cc8415"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
